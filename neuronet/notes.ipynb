{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var = Variable(torch.randn(100, 3, 84, 84))\n",
    "# n_features = 64\n",
    "# lc1 = nn.Conv2d(3, n_features, 4, 2, 1, bias=False)\n",
    "# lc2 = nn.Conv2d(n_features, n_features * 2, 4, 2, 0, bias=False)\n",
    "# lc3 = nn.Conv2d(n_features*2, n_features*4, 4,2,1,bias=False)\n",
    "# lp1 = nn.MaxPool2d(2)\n",
    "# ll1 = nn.Linear(int(n_features*4*5*5/640), 640)\n",
    "# vl1 = lc1(var)\n",
    "# print(\"vl1\\n\", vl1.size())\n",
    "# vl2 = lc2(vl1)\n",
    "# print(\"vl2\\n\", vl2.size())\n",
    "# vl3 = lp1(vl2)\n",
    "# print(\"vl3\\n\", vl3.size())\n",
    "# vl4 = lc3(vl3)\n",
    "# print(\"vl4\\n\", vl4.size())\n",
    "# vl4 = vl4.view(-1, 640)\n",
    "# print(\"vl4\\n\", vl4.size())\n",
    "# vl5 = ll1(vl4)\n",
    "# print(\"vl5\\n\", vl5.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms, datasets\n",
    "import torch.utils.data\n",
    "\n",
    "\n",
    "CUDA = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "class MagnusNet(nn.Module):\n",
    "    \n",
    "    @staticmethod\n",
    "    def no_dim_reduction_conv(in_channels, out_channels, padding=1, bias=False):\n",
    "        return nn.Conv2d(in_channels, out_channels, 3, 1, padding, bias=bias)\n",
    "    \n",
    "    @staticmethod\n",
    "    def half_dim_reduction_conv(in_channels, out_channels, padding=1, bias=False):\n",
    "        return nn.Conv2d(in_channels, out_channels, 4, 2, padding, bias=bias)\n",
    "    \n",
    "    def __init__(self, n_features):\n",
    "        super(MagnusNet, self).__init__()\n",
    "        self.n_features = n_features\n",
    "        self.convnet = nn.Sequential(\n",
    "            MagnusNet.half_dim_reduction_conv(3, n_features),\n",
    "            nn.BatchNorm2d(n_features),\n",
    "            nn.LeakyReLU(0.1, True),\n",
    "            \n",
    "            MagnusNet.half_dim_reduction_conv(n_features, n_features * 2, 0),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(n_features*2),\n",
    "            nn.LeakyReLU(0.1, True),\n",
    "            \n",
    "            MagnusNet.half_dim_reduction_conv(n_features * 2, n_features * 4),\n",
    "            nn.BatchNorm2d(n_features*4),\n",
    "            nn.LeakyReLU(0.1, True),\n",
    "            nn.Conv2d(n_features * 4, n_features * 4, 5),\n",
    "        )\n",
    "        self.linearnet = nn.Sequential(\n",
    "            nn.Linear(n_features * 4, n_features),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(n_features, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.convnet(x)\n",
    "        x = x.view(-1, self.n_features*4)\n",
    "        x = self.linearnet(x)\n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def net_instance(n_features):\n",
    "        instance = MagnusNet(n_features)\n",
    "        if CUDA:\n",
    "            instance.cuda()\n",
    "        return instance\n",
    "\n",
    "batch_size = 3\n",
    "n_epochs = 10\n",
    "n_features = 64\n",
    "\n",
    "dataset = datasets.ImageFolder(root='/opt/ProjectsPy/neurohack/neurodata/neuro-train',\n",
    "                                   transform=transforms.Compose([\n",
    "                                       transforms.ToTensor()\n",
    "                                   ])\n",
    "                                   )\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size, shuffle=True)\n",
    "\n",
    "testset = datasets.ImageFolder(root='/opt/ProjectsPy/neurohack/neurodata/neuro-test',\n",
    "                                   transform=transforms.Compose([\n",
    "                                       transforms.ToTensor()\n",
    "                                   ])\n",
    "                                   )\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size, shuffle=True)\n",
    "\n",
    "model = MagnusNet.net_instance(n_features)\n",
    "\n",
    "learning_rate = 0.01\n",
    "beta_one = 0.81\n",
    "beta_two = 0.999\n",
    "optimizer = optim.Adam(model.parameters(), learning_rate, (beta_one, beta_two))\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for i, (x, label) in enumerate(dataloader):\n",
    "        label = label.float()\n",
    "        if CUDA:\n",
    "            x, label = x.cuda(), label.cuda()\n",
    "        x, label = Variable(x), Variable(label)\n",
    "        model.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, i * len(x), len(dataloader.dataset),\n",
    "                   100. * i / len(dataloader), loss.data[0]))\n",
    "            \n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (x, label) in enumerate(testloader):\n",
    "        int_label = torch.LongTensor(label)\n",
    "        label = label.float()\n",
    "        if CUDA:\n",
    "            x, label = x.cuda(), label.cuda()\n",
    "        x, label = Variable(x, volatile=True), Variable(label)\n",
    "        output = model(x)\n",
    "        test_loss += criterion(output, label)\n",
    "        output_tensor = output.data\n",
    "        output_tensor = output_tensor.apply_(lambda x: 0.0 if x < 0.5 else 1.0)\n",
    "        onp = output_tensor.numpy().flatten()\n",
    "        lnp = int_label.numpy()\n",
    "        correct += (onp == lnp).sum()\n",
    "        total += int_label.size()[0]\n",
    "    test_loss = test_loss.data.cpu().numpy()[0] / total\n",
    "    \n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{}\\n'.format(\n",
    "        test_loss, correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "convnet = nn.Sequential(\n",
    "            MagnusNet.half_dim_reduction_conv(3, n_features),\n",
    "            nn.BatchNorm2d(n_features),\n",
    "            nn.LeakyReLU(0.1, True),\n",
    "            \n",
    "            MagnusNet.half_dim_reduction_conv(n_features, n_features * 2, 0),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(n_features*2),\n",
    "            nn.LeakyReLU(0.1, True),\n",
    "            \n",
    "            MagnusNet.half_dim_reduction_conv(n_features * 2, n_features * 4),\n",
    "            nn.BatchNorm2d(n_features*4),\n",
    "            nn.LeakyReLU(0.1, True),\n",
    "            nn.Conv2d(n_features * 4, n_features * 4, 5),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearnet = nn.Sequential(\n",
    "            nn.Linear(n_features*4, n_features),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(n_features, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "co torch.Size([3, 256, 1, 1])\nco torch.Size([3, 256])\nlo torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.randn(3, 3, 84, 84))\n",
    "co = convnet(x)\n",
    "print('co', co.size())\n",
    "co = co.view(-1, n_features*4)\n",
    "print('co', co.size())\n",
    "lo = linearnet(co)\n",
    "print('lo', lo.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nTest set: Average loss: 0.0993, Accuracy: 5/10\n\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
